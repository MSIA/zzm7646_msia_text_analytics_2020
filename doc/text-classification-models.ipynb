{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/zazhu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/zazhu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from io import StringIO\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import math\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import fasttext\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/Corona_NLP_train.csv\",encoding='latin1')\n",
    "test = pd.read_csv(\"../data/Corona_NLP_test.csv\",encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName   Location     TweetAt  \\\n",
       "0      3799       48751     London  16-03-2020   \n",
       "1      3800       48752         UK  16-03-2020   \n",
       "2      3801       48753  Vagabonds  16-03-2020   \n",
       "3      3802       48754        NaN  16-03-2020   \n",
       "4      3803       48755        NaN  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1  advice Talk to your neighbours family to excha...            Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3  My food stock is not the only one which is emp...            Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive              0.277523\n",
       "Negative              0.240955\n",
       "Neutral               0.187404\n",
       "Extremely Positive    0.160945\n",
       "Extremely Negative    0.133173\n",
       "Name: Sentiment, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'] = train.OriginalTweet\n",
    "train[\"text\"] = train[\"text\"].astype(str)\n",
    "\n",
    "test['text'] = test.OriginalTweet\n",
    "test[\"text\"] = test[\"text\"].astype(str)\n",
    "\n",
    "# Data has 5 classes\n",
    "train.Sentiment.value_counts(normalize= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    '''tokenize and normalize'''\n",
    "\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "\n",
    "    # convert to dataframe\n",
    "    data = pd.DataFrame({'text': x.text, 'label': x.Sentiment})\n",
    "\n",
    "    # remove html\n",
    "    data['text'] = data.apply(lambda t: re.sub(r'https?://\\S+|www\\.\\S+', '', str(t['text'])), axis=1)\n",
    "\n",
    "    # remove stopwords, number, and convert to lower case\n",
    "    data['text'] = data.apply(lambda r: ' '.join(w.lower() for w in r['text'].split() if (w.lower() not in stop_words) & (w.isalpha())),axis=1)\n",
    "    data['text'] = data[data['text'] != '']\n",
    "    \n",
    "    # discard NA reviews\n",
    "    data = data.dropna()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "train_new = preprocess(train)\n",
    "test_new = preprocess(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advice talk neighbours family exchange phone n...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coronavirus woolworths give disabled dedicated...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>food stock one enough food everyone take stay ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ready go supermarket food stock litteraly seri...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>news first confirmed case came sullivan county...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text               label\n",
       "1  advice talk neighbours family exchange phone n...            Positive\n",
       "2  coronavirus woolworths give disabled dedicated...            Positive\n",
       "3  food stock one enough food everyone take stay ...            Positive\n",
       "4  ready go supermarket food stock litteraly seri...  Extremely Negative\n",
       "5  news first confirmed case came sullivan county...            Positive"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = (1,2)\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5,ngram_range=ngram, stop_words='english')\n",
    "tfidf.fit_transform(train_new.text.values)\n",
    "\n",
    "# We transform each text into a vector\n",
    "x_train = tfidf.transform(train_new.text.values)\n",
    "x_test = tfidf.transform(test_new.text.values)\n",
    "y_train = train_new.label.values\n",
    "y_test = test_new.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best performing svm model\n",
    "with open('tfidf_vec.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5004\n",
      "Micro-averaged F1 score: 0.5004\n"
     ]
    }
   ],
   "source": [
    "lr1 = LogisticRegression(random_state=66)  # fit logistic\n",
    "lr1.fit(x_train, y_train)\n",
    "y_pred = lr1.predict(x_test) # predict\n",
    "\n",
    "# evaluation metrics\n",
    "print(\"Accuracy: %0.4f\"%accuracy_score(y_test, y_pred))\n",
    "print(\"Micro-averaged F1 score: %0.4f\"%f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5036\n",
      "Micro-averaged F1 score: 0.5036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.1s finished\n"
     ]
    }
   ],
   "source": [
    "lr2 = LogisticRegression(verbose=1, random_state=66, C=15, penalty='l2')  # fit logistic\n",
    "lr2.fit(x_train, y_train)\n",
    "y_pred = lr2.predict(x_test) # predict\n",
    "\n",
    "# evaluation metrics\n",
    "print(\"Accuracy: %0.4f\"%accuracy_score(y_test, y_pred))\n",
    "print(\"Micro-averaged F1 score: %0.4f\"%f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5104\n",
      "Micro-averaged F1 score: 0.5104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.6s finished\n"
     ]
    }
   ],
   "source": [
    "lr3 = LogisticRegression(verbose=1, random_state=66, C=5, penalty='l2')\n",
    "lr3.fit(x_train, y_train)\n",
    "y_pred = lr3.predict(x_test) # predict\n",
    "\n",
    "# evaluation metrics\n",
    "print(\"Accuracy: %0.4f\"%accuracy_score(y_test, y_pred))\n",
    "print(\"Micro-averaged F1 score: %0.4f\"%f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Accuracy: 0.4978\n",
      "Micro-averaged F1 score: 0.4978\n"
     ]
    }
   ],
   "source": [
    "lr4 = LogisticRegression(verbose=1, random_state=66, C=5, penalty='l1', solver='liblinear')\n",
    "lr4.fit(x_train, y_train)\n",
    "y_pred = lr4.predict(x_test) # predict\n",
    "\n",
    "# evaluation metrics\n",
    "print(\"Accuracy: %0.4f\"%accuracy_score(y_test, y_pred))\n",
    "print(\"Micro-averaged F1 score: %0.4f\"%f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Accuracy: 0.5199\n",
      "Micro-averaged F1 score: 0.5199\n"
     ]
    }
   ],
   "source": [
    "lr5 = LogisticRegression(verbose=1, random_state=66, C=1, penalty='l1', solver='liblinear')\n",
    "lr5.fit(x_train, y_train)\n",
    "y_pred = lr5.predict(x_test) # predict\n",
    "\n",
    "# evaluation metrics\n",
    "print(\"Accuracy: %0.4f\"%accuracy_score(y_test, y_pred))\n",
    "print(\"Micro-averaged F1 score: %0.4f\"%f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.7805\n"
     ]
    }
   ],
   "source": [
    "# fasttext requires data to be in the format of: __label__1 text\n",
    "train_fasttext = train_new.apply(lambda t: '__label__' + str(t['label']) + ' ' + str(t['text']), axis=1)\n",
    "test_fasttext = test_new.apply(lambda t: '__label__' + str(t['label']) + ' ' + str(t['text']), axis=1)\n",
    "train_fasttext.to_csv('fasttext_train.txt',index=False, header=False)\n",
    "test_fasttext.to_csv('fasttext_test.txt',index=False, header=False)\n",
    "\n",
    "# fasttext model - default\n",
    "ft_model1 = fasttext.train_supervised('fasttext_train.txt')\n",
    "\n",
    "# calculate evaluation metrics\n",
    "result = ft_model1.test('fasttext_test.txt')\n",
    "precision = result[1]\n",
    "recall = result[2]\n",
    "print(\"F1 score: %0.4f\"%(2*precision*recall/(precision+recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.7637\n"
     ]
    }
   ],
   "source": [
    "# fasttext model - setting 1\n",
    "ft_model2 = fasttext.train_supervised('fasttext_train.txt',wordNgrams=2)\n",
    "result = ft_model2.test('fasttext_test.txt')\n",
    "precision = result[1]\n",
    "recall = result[2]\n",
    "print(\"F1 score: %0.4f\"%(2*precision*recall/(precision+recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.7647\n"
     ]
    }
   ],
   "source": [
    "# fasttext model - setting 2\n",
    "ft_model3 = fasttext.train_supervised('fasttext_train.txt',lr=0.1, wordNgrams=2)\n",
    "result = ft_model3.test('fasttext_test.txt')\n",
    "precision = result[1]\n",
    "recall = result[2]\n",
    "print(\"F1 score: %0.4f\"%(2*precision*recall/(precision+recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.7639\n"
     ]
    }
   ],
   "source": [
    "# fasttext model - setting 3\n",
    "ft_model4 = fasttext.train_supervised('fasttext_train.txt', wordNgrams=2, loss='softmax')\n",
    "result = ft_model4.test('fasttext_test.txt')\n",
    "precision = result[1]\n",
    "recall = result[2]\n",
    "print(\"F1 score: %0.4f\"%(2*precision*recall/(precision+recall)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4730\n",
      "Micro-averaged F1 score: 0.4730\n"
     ]
    }
   ],
   "source": [
    "svm1 = LinearSVC(random_state=66)\n",
    "svm1.fit(x_train, y_train)\n",
    "y_pred = svm1.predict(x_test)\n",
    "\n",
    "print(\"Accuracy: %0.4f\"%accuracy_score(y_test, y_pred))\n",
    "print(\"Micro-averaged F1 score: %0.4f\"%f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4635\n",
      "Micro-averaged F1 score: 0.4635\n"
     ]
    }
   ],
   "source": [
    "svm2 = LinearSVC(random_state=66, loss='hinge', C=5)\n",
    "svm2.fit(x_train, y_train)\n",
    "y_pred = svm2.predict(x_test)\n",
    "\n",
    "print(\"Accuracy: %0.4f\"%accuracy_score(y_test, y_pred))\n",
    "print(\"Micro-averaged F1 score: %0.4f\"%f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4732\n",
      "Micro-averaged F1 score: 0.4732\n"
     ]
    }
   ],
   "source": [
    "svm3 = LinearSVC(random_state=66, penalty='l2', loss='hinge', max_iter=500)\n",
    "svm3.fit(x_train, y_train)\n",
    "y_pred = svm3.predict(x_test)\n",
    "\n",
    "print(\"Accuracy: %0.4f\"%accuracy_score(y_test, y_pred))\n",
    "print(\"Micro-averaged F1 score: %0.4f\"%f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4996\n",
      "Micro-averaged F1 score: 0.4996\n"
     ]
    }
   ],
   "source": [
    "svm4 = LinearSVC(random_state=66, penalty='l1', loss='squared_hinge',max_iter=500, dual=False)\n",
    "svm4.fit(x_train, y_train)\n",
    "y_pred = svm4.predict(x_test)\n",
    "\n",
    "print(\"Accuracy: %0.4f\"%accuracy_score(y_test, y_pred))\n",
    "print(\"Micro-averaged F1 score: %0.4f\"%f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4996\n",
      "Micro-averaged F1 score: 0.4996\n"
     ]
    }
   ],
   "source": [
    "svm5 = LinearSVC(random_state=66, penalty='l1', loss='squared_hinge', dual=False)\n",
    "svm5.fit(x_train, y_train)\n",
    "y_pred = svm5.predict(x_test)\n",
    "\n",
    "print(\"Accuracy: %0.4f\"%accuracy_score(y_test, y_pred))\n",
    "print(\"Micro-averaged F1 score: %0.4f\"%f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(class_weight='balanced', max_depth=50, n_estimators=200)\n"
     ]
    }
   ],
   "source": [
    "max_depth = [10,30,50]\n",
    "n_estimators = [200,500]\n",
    "grid_params ={'max_depth':max_depth,'n_estimators':n_estimators}\n",
    "\n",
    "RandomFoest_model = GridSearchCV(RandomForestClassifier(class_weight = 'balanced'), grid_params,\n",
    "                  scoring = 'accuracy', cv=5,n_jobs=-1, return_train_score=True)\n",
    "RandomFoest_model.fit(x_train, y_train)\n",
    "\n",
    "results = pd.DataFrame.from_dict(RandomFoest_model.cv_results_)\n",
    "print(RandomFoest_model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4289\n",
      "Micro-averaged F1 score: 0.4289\n"
     ]
    }
   ],
   "source": [
    "RandomFoest_model = RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
    "                                      max_depth=50, n_estimators=200,  random_state=66, verbose=0)\n",
    "RandomFoest_model.fit(x_train,y_train)\n",
    "\n",
    "y_pred = RandomFoest_model.predict(x_test)\n",
    "print(\"Accuracy: %0.4f\"%accuracy_score(y_test, y_pred))\n",
    "print(\"Micro-averaged F1 score: %0.4f\"%f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store best model\n",
    "ft_model1.save_model('fasttext_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"0__label: Extremely Negative\": {\n",
      "    \"predicted label\": \"__label__Neutral\",\n",
      "    \"Probability\": 0.9999134540557861\n",
      "  },\n",
      "  \"1__label: Extremely Positive\": {\n",
      "    \"predicted label\": \"__label__Positive\",\n",
      "    \"Probability\": 0.9997422099113464\n",
      "  },\n",
      "  \"2__label: Negative\": {\n",
      "    \"predicted label\": \"__label__Negative\",\n",
      "    \"Probability\": 0.8929682970046997\n",
      "  },\n",
      "  \"3__label: Neutral\": {\n",
      "    \"predicted label\": \"__label__Negative\",\n",
      "    \"Probability\": 0.9983593225479126\n",
      "  },\n",
      "  \"4__label: Positive\": {\n",
      "    \"predicted label\": \"__label__Positive\",\n",
      "    \"Probability\": 0.999428391456604\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# read fasttext model and tfidf tranformer\n",
    "loaded_model = fasttext.load_model('model/fasttext_model')\n",
    "\n",
    "comment = ['I HATE COVID',\n",
    "        'Stay strong and we can make it!',\n",
    "        \"It's fucking horrible that I can't even breath inside the mask.\",\n",
    "        'Life is bad but we have to stay at home.',\n",
    "        'Life will be better when the vaccine comes out.']\n",
    "\n",
    "label = ['Extremely Negative', 'Extremely Positive', 'Negative', 'Neutral', 'Positive']\n",
    "\n",
    "\n",
    "result = {}\n",
    "for i in range(len(label)):\n",
    "    predict = loaded_model.predict(comment[i])\n",
    "    result[str(i) + '__label: ' + str(label[i])] = {'predicted label': predict[0][0],\n",
    "                                           'Probability': predict[1][0]}\n",
    "\n",
    "# save results\n",
    "with open('predcition.json', 'w') as f:\n",
    "    json.dump(result, f)\n",
    "\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
